# -*- coding: utf-8 -*-
"""Python_RFM_Recency_Frequency_Monetary_KMeans.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n0Zi6fW8nIYjBxGD_pUbRyePrU-RWo7t

#Recency

#When did the customer interact with the company recently and how long has it been since the last time?
"""

import pandas as pd

df = pd.read_csv("orders.csv")
df = df.loc[df['city_name_fa'] == 'تهران']
print("Min_Date:", df['DateTime_CartFinalize'].min(), ", Max_Date:", df['DateTime_CartFinalize'].max())
df['DateTime_CartFinalize'] = df['DateTime_CartFinalize'].astype(str)
df['DateTime_CartFinalize'] = df['DateTime_CartFinalize'].str.replace('\D', '').astype(int)

recency = (df['DateTime_CartFinalize'].max() - df.groupby("ID_Customer").agg({"DateTime_CartFinalize":"max"}).rename(columns = {"DateTime_CartFinalize":"Recency"}))
recency
recency.to_csv('recency.csv')

"""#Frequency

###The number of times a customer orders or purchases in a specific period of time. The higher the value of this variable, the greater the customer loyalty.
"""

frequency = df.groupby("ID_Customer").agg({"DateTime_CartFinalize":"nunique"}).rename(columns={"DateTime_CartFinalize": "Frequency"})
print(frequency)
frequency.to_csv('frequency.csv')

"""#Monetary

######Financial transaction volume, how much financial transaction did the customer have with the company during a specific period of time? The higher the value of this variable, the more importance the company should attach to this customer.
"""

df["TotalPrice"] = df["Amount_Gross_Order"] * df["Quantity_item"]

monetary = df.groupby("ID_Customer").agg({"TotalPrice":"sum"}).rename(columns={"TotalPrice":"Monetary"})
print(monetary)
monetary.to_csv('monetary.csv')

FM = monetary.merge(frequency, on = "ID_Customer", how = "inner")
RFM = FM.merge(recency, on = "ID_Customer")
RFM.head()

"""#K-Mean Clustering"""

# Commented out IPython magic to ensure Python compatibility.
#Importing Libraries
import pandas as pd

# For Visualisation
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

# To Scale our data
from sklearn.preprocessing import scale

# To perform KMeans clustering
from sklearn.cluster import KMeans

# To perform Hierarchical clustering
from scipy.cluster.hierarchy import linkage
from scipy.cluster.hierarchy import dendrogram
from scipy.cluster.hierarchy import cut_tree

"""#Outlier treatment for Monatery - Amount"""

plt.boxplot(RFM.Monetary)
Q1 = RFM.Monetary.quantile(0.25)
Q3 = RFM.Monetary.quantile(0.75)
IQR = Q3 - Q1
RFM = RFM[(RFM.Monetary >= (Q1 - 1.5*IQR)) & (RFM.Monetary <= (Q3 + 1.5*IQR))]

"""#Outlier treatment for Frequency"""

plt.boxplot(RFM.Frequency)
Q1 = RFM.Frequency.quantile(0.25)
Q3 = RFM.Frequency.quantile(0.75)
IQR = Q3 - Q1
RFM = RFM[(RFM.Frequency >= Q1 - 1.5*IQR) & (RFM.Frequency <= Q3 + 1.5*IQR)]

"""#Outlier treatment for Recency"""

plt.boxplot(RFM.Recency)
Q1 = RFM.Recency.quantile(0.25)
Q3 = RFM.Recency.quantile(0.75)
IQR = Q3 - Q1
RFM = RFM[(RFM.Recency >= Q1 - 1.5*IQR) & (RFM.Recency <= Q3 + 1.5*IQR)]

RFM.head(20)

"""#Scaling the RFM data
#Standardise all parameters
"""

RFM_norm1 =  RFM
RFM_norm1
from sklearn.preprocessing import StandardScaler
standard_scaler = StandardScaler()
RFM_norm1 = standard_scaler.fit_transform(RFM_norm1)
RFM_norm1 = pd.DataFrame(RFM_norm1)
RFM_norm1
RFM_norm1.columns = ['Frequency','Monetary','Recency']
RFM_norm1.head()

"""#Hopkins Statistics:"""

from sklearn.neighbors import NearestNeighbors
from random import sample
from numpy.random import uniform
import numpy as np
from math import isnan

def hopkins(X):
    d = X.shape[1]
    #d = len(vars) # columns
    n = len(X) # rows
    m = int(0.1 * n)
    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)
    rand_X = sample(range(0, n, 1), m)

    ujd = []
    wjd = []
    for j in range(0, m):
        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)
        ujd.append(u_dist[0][1])
        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)
        wjd.append(w_dist[0][1])

    H = sum(ujd) / (sum(ujd) + sum(wjd))
    if isnan(H):
        print(ujd, wjd)
        H = 0
    return H

hopkins(RFM_norm1)

"""#K-Means with some K

###Kmeans with K=3
"""

model_clus5 = KMeans(n_clusters = 3, max_iter=50)
model_clus5.fit(RFM_norm1)

"""##Silhouette Analysis

![image.png](data:image/png;base64,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)

p  is the mean distance to the points in the nearest cluster that the data point is not a part of

q is the mean intra-cluster distance to all the points in its own cluster.

The value of the silhouette score range lies between -1 to 1.

A score closer to 1 indicates that the data point is very similar to other data points in the cluster,

A score closer to -1 indicates that the data point is not similar to the data points in its cluster.

#Silhouette Score For K
"""

from sklearn.metrics import silhouette_score
sse_ = []
for k in range(2, 5):
    kmeans = KMeans(n_clusters=k).fit(RFM_norm1)

    sse_.append([k, silhouette_score(RFM_norm1, kmeans.labels_)])
    print(sse_ )

plt.plot(pd.DataFrame(sse_)[0], pd.DataFrame(sse_)[1]);

"""##Sum of Squared Distances"""

# sum of squared distances
ssd = []
for num_clusters in list(range(1,21)):
    model_clus = KMeans(n_clusters = num_clusters, max_iter=50)
    model_clus.fit(RFM_norm1)
    ssd.append(model_clus.inertia_)

plt.plot(ssd)

pd.RangeIndex(len(RFM.index))

# analysis of clusters formed
RFM.index = pd.RangeIndex(len(RFM.index))
RFM_km = pd.concat([RFM, pd.Series(model_clus5.labels_)], axis=1)
RFM_km.columns = [ 'Recency','Frequency','Monetary' , 'ClusterID']

km_clusters_recency = 	pd.DataFrame(RFM_km.groupby(["ClusterID"]).Recency.mean())
km_clusters_frequency = 	pd.DataFrame(RFM_km.groupby(["ClusterID"]).Frequency.mean())
km_clusters_amount = 	pd.DataFrame(RFM_km.groupby(["ClusterID"]).Monetary.mean())

km_clusters_recency

km_clusters_amount

RFM_km.head()

df = pd.concat([pd.Series([0,1,2]), km_clusters_amount, km_clusters_frequency, km_clusters_recency], axis=1)
df.columns = ["ClusterID", 'Monetary' ,'Recency','Frequency']
df.info()

"""#Monetary Cluster For K=3"""

sns.barplot(x=df.ClusterID, y=df.Monetary)

"""#Frequency Cluster For K=3





"""

sns.barplot(x=df.ClusterID, y=df.Frequency)

"""#Recency Cluster For K=3"""

sns.barplot(x=df.ClusterID, y=df.Recency)

RFM_km = pd.concat([RFM_km, pd.Series(model_clus5.labels_)], axis=1)
RFM_km

"""#Find less Monatery cluster which is the first cluster. This shows amount of money that customers has spent. So, this is the lowest and then we can find the Customer Id who has less amount and then find and recommend cheap item to this group of customers."""

df.Monetary[1]

df_Monetary =  monetary.loc[monetary['Monetary'] < df.Monetary[1]]

df_Monetary

df_Monetary.to_csv('df_Monetary.csv')
df_Cheapest = pd.read_csv("df_Monetary.csv")
df_Cheapest.columns = ["ID_Customer", 'Monetary' ]

df_Cheapest.ID_Customer

df = pd.read_csv("orders.csv")
ID_Item=[]
for i in df_Cheapest.ID_Customer:
  df_seek = df.loc[df['ID_Customer'] == i]
  ID_Item.append(df_seek.ID_Item)

ID_Item

"""#Find high Monatery cluster which is the zero cluster. This shows amount of money that customers has spent. So, this is the largest and then we can find the Customer Id who has the most amount and then find and recommend expensive item to this group of customers."""

df.Monetary[0]

df_Rec =  monetary.loc[monetary['Monetary'] < df.Monetary[0]]

df_Rec
df_Rec.to_csv('df_Rec_Expensive.csv')
df_Expensive = pd.read_csv("df_Rec_Expensive.csv")
df_Expensive.columns = ["ID_Customer", 'Monetary' ]

df_Expensive.ID_Customer

df = pd.read_csv("orders.csv")
ID_Item_Expensive=[]
for i in df_Expensive.ID_Customer:
  df_seek_Expensive = df.loc[df['ID_Customer'] == i]
  ID_Item.append(df_seek_Expensive.ID_Item)

ID_Item_Expensive